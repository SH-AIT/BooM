# llm_solution

2025年，以DeepSeek-R1为代表的AI大模型正以惊人的速度重塑产业格局。短短7天用户破亿、多模态交互与低算力需求突破硬件限制，这些成就印证了AI技术走向规模落地的临界点已至。然而，将AI融入到具体产业，还面临着一些问题：

**从产业上看：**

1、**算力与模型的割裂**：厂商需为不同硬件重复适配模型，开发成本陡增；

2、**生态孤岛化**：各厂商自建技术栈，导致跨平台协作效率低下；

3、**长尾需求难满足**：中小开发者受限于算力与框架兼容性，难以复用头部模型能力。

**从技术上看：**

1、**混合专家（MoE）架构的适配性挑战**：专家模型与硬件内存存在匹配困境，同时专家负载不均与通信开销过高；

2、**多模型协同与训推一体的系统挑战**：多模型动态交互、训推状态切换、资源动态分配引发协同困难，训推一体化软件栈的易用性不足；

3、**长序列推理与稀疏计算的性能挑战**：长序列KVCache存在容量瓶颈；稀疏计算引发的向量化效率下降。

DeepSeek引发的挑战本质上是AI规模化落地的必经之痛。解决这些难题需硬件厂商、框架开发者与行业用户深度协同，通过**全栈开放生态共建**与**分层协同性能提升**，实现从单点突破到系统级效能跃迁。

为了解决以上问题，**openEuler开源社区与MindSpore社区**，推出面向大模型的全栈开源方案，以**操作系统+AI框架+模型生态**的三层开放架构，替换**操作系统**和**DL框架**，秉承**代码开源+标准开放+生态共建**的理念，打造智能时代的全国产化的数字基座。

## 软件架构
### 全栈开放生态共建

![](/doc/deepseek/asserts/software_stack.png)


openEuler+MindSpore社区协同提出开源推理方案，以全栈开放架构直击痛点：

**1. 对上：兼容多元大模型生态，普惠AI**

a、支持DeepSeek、LLaMA系列等主流模型接入，通过归一化的开源推理软件栈，保证不同模型对资源的动态调配，在生态上做到统一演进，且开箱即优，避免"重复造轮子"；

b、集成模型微调与蒸馏能力，优化增强RAG流程搭建，结合DeepSeek群体策略优化经验，降低长尾场景定制门槛。

**2. 对下：异构算力无缝接入，AI基座**

a、通过硬件抽象层兼容GPU、NPU及国产芯片，释放DeepSeek低能耗技术红利；

b、在极致资源约束下，资源动态调度诉求强烈，通过全栈协同优化降低模型资源消耗获得竞争优势。



### 分层协同性能提升

通过openEuler、MindSpore与vLLM/RAY间的分层协同，为DeepSeek-R1大模型带来了吞吐性能与易用性的显著提升。核心技术点如下：

#### openEuler：

##### 异构融合调度：负载感知MoE冷热专家，任务细粒度调度提升推理性能

1.  负载感知的冷热MoE专家动态识别和并行调度，稀疏MoE计算分层细粒度拆分到不同进程部署在多样算力；

2.  共享资源细粒度按需控制，支持MoE专家均衡调度，计算/通信细粒度并发；

3.  针对高并发场景下推理服务、分布式计算组件Host侧资源争用的痛点，利用NUMA感知的细粒度算力与内存资源隔离，提升推理整体性能。

##### 异构融合内存：高效管理异构内存，减小系统内存碎片，提升系统推理性能

1.  针对推理服务高并发场景，通过线程特性感知的细粒度内存分配、高性能代码段大页机制，在控制内存开销的同时，提升Host侧性能与整体推理吞吐；

2.  针对MoE架构的稀疏访存特征，通过Host/Device协同内存管理实现多粒度动态混合页与按需内存分配，减少页表访存开销同时提升显存利用效率；

3.  针对大模型推理服务面临的显存容量挑战，基于MoE架构的稀疏计算特征，利用运行时-OS协同设计实现高效专家超分部署，提升显存利用率与整体推理吞吐。

##### 异构融合编译：毕昇编译优化，减少算子下发耗时，提升算子性能

1.  **架构亲和编译优化**：通过架构亲和的原子指令优化和Malloc、Memcpy高性能库优化，降低各类锁的代价，提高内存利用效率，降低访存开销，进而降低时延，提高吞吐率；算子编译阶段使能智能感知流水优化，基于数据依赖关系深度分析和自适应同步决策机制，自动插入最优同步指令实现高效的多级流水并行；通过昇腾算子抽象层与芯片ISA的智能映射，实现指令级并行优化，极大发挥芯片理论算力；

2.  **多维融合编译优化**：针对算子下发阶段前端性能瓶颈较高的特点，通过CFGO优化技术，借助运行时信息，编译器进行精准的代码布局优化，有效提高程序IPC，降低算子下发时延；多维融合加速能够自动实现向量类算子融合、矩阵-向量类算子融合，减少数据搬运开销，并通过细粒度并行进一步提升算子性能，快速满足用户验证模型算法和提升模型开箱性能。

#### MindSpore：

##### 图编译：将模型编译为计算图，通过模式匹配自动将小算子融为大算子

1\.**图生成**：MindSpore通过JIT编译自动将模型的python类或者函数编译成一张完整的计算图，JIT编译提供了多种方式(ast/bytecode/trace）以满足不同场景的用途，覆盖了绝大部分Python语法。

2\.**自动融合**：基于计算图通过自动模式匹配实现算子融合，将小算子融合成大颗粒的算子。大算子既减少Host下发的开销，同时也大大缩短了Device的计算时延。在DeepSeek V3/R1模型中实现了QKV/FFN+Split融合、Transpose+BatchMatMul+Transpose融合、Swiglu融合以及Norm类融合，大幅度减少了算子数量。

3\.**动态shape支持**：计算图的执行需要支持动态shape以满足推理场景输入输出序列长度以及batch
size的动态变化，相比于静态shape的整图下沉，动态shape的计算图执行需要每个iteration在Host侧重新执执行shape推导以及申请显存等操作，为了避免Host成为瓶颈，MindSpore通过Shape推导和显存申请、算子Tiling数据计算以及算子下发三级流水优化，实现Host计算和Device计算的掩盖。

##### 模型压缩：金箍棒工具，快速实现模型量化算法及量化推理全流程

金箍棒是华为昇思 MindSpore团队与华为诺亚方舟实验室联合研发的模型压缩工具，依靠 MindSpore Rewrite
模块，为算法开发者屏蔽网络差异和硬件细节，提升算法接入与调优效率，同时提供了可视化、量化损失分析以及Summary等工具。

我们使用金箍棒通过不同量化方式，来尝试平衡DeepSeek-R1的精度和性能：

**8bit权重量化**：对 DeepSeek-R1 进行8bit权重量化，使权重显存占用降为1/2，小batch_size场景推理性能提升明显，但大batch_size场景推理性能变差，分析发现是权重量化矩阵乘算子随着batch_size增大性能会下降。

**SmoothQuant 8bit量化**：为提升大batch_size场景的性能，用SmoothQuant 8bit
全量化，测试发现随batch_size增加，吞吐量线性度良好，但网络量化精度损失仍较大。

**混合量化**：为降量化精度损失，对精度较敏感的FeedForward层用激活动态量化，损失部分性能提升来提升量化精度，MLA层用Outlier-Suppression+异常值抑制算法替代SmoothQuant进一步提升精度。




## 全栈解决方案部署教程

### DeepSeek V3&R1部署

参考[部署指南](https://gitee.com/openeuler/llm_solution/blob/master/doc/deepseek/DeepSeek-V3&R1%E9%83%A8%E7%BD%B2%E6%8C%87%E5%8D%97.md)，使用一键式部署脚本，20min完成推理服务拉起

### EulerCopilot部署

参考[EulerCopilot用户指南](https://gitee.com/openeuler/euler-copilot-framework/blob/master/docs/user-guide/README.md)，搭建本地知识库并协同DeepSeek大模型完成智能调优、智能运维等应用；



## 性能

### 精度

本方案使用8bit权重量化、SmoothQuant
8bit量化和混合量化等技术，最终以CEval精度损失2分的代价，实现了DeepSeek-R1w8a8的大模型部署。

| 模型                   | CEval精度 |
| ---------------------- | --------- |
| Claude-3.5-Sonnet-1022 | 76.7      |
| GPT-4o 0513            | 76        |
| DeepSeek V3            | 86.5      |
| GPT-4o 0513            | 76        |
| OpenAI o1-mini         | 68.9      |
| DeepSeek R1            | 91.8      |
| Deepseek R1 w8a8       | 89.52     |



### 吞吐

测试环境：

1.  两台Atlas 800I A2（8\*64G）。
2.  Ascend HDK Driver 24.1.0版本，Firmware 7.5.0.3.22版本。
3.  openEuler 22.03 LTS版本（内核 5.10）。

| 并发数 | 吞吐(Token/s) |
| ------ | ------------- |
| 1      | 16.7          |
| 192    | 1188          |



## 参与贡献

欢迎通过issue方式提出您宝贵的建议，共建开箱即优、性能领先的全栈开源国产化推理解决方案
# llm_solution
